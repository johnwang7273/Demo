# This is for RBC assignment
```
Assignment:  Install\deploy Kafka within a Docker container and demonstrate the data flow between a sample producer and consumer. Documentation should be provided to explain the end-to-end elements and relationships when using Kafka as a message broker between producer and consumer services.

Submission format: Please send a GitHub/Bitbucket source code repository link.

```

# Please see wiki page for more info
<a href="https://github.com/johnwang7273/Demo/wiki">wiki Home</a><br/>
<a href="https://github.com/johnwang7273/Demo/wiki/Kafka-Broker-runtime-and-Producer-Consumer-interaction">Kafka Broker runtime and Producer Consumer interaction</a><br/>         


# Kafka Producer/Consumer basics
Kafka can be used with Apache Storm to handle data pipeline for high speed filtering and pattern matching on the fly. Kafka is often used for operation monitoring data pipelines. This involves aggregating statistics from distributed applications to produce centralized feeds of operational data.
![](https://github.com/johnwang7273/Demo/blob/master/kafka-comsumer-provider.png)
